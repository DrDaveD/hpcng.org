<?xml version="1.0" encoding="UTF-8"?><rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title><![CDATA[HPCng]]></title><description><![CDATA[HPCng is an open community of people and organizations interested in the broad modernization of HPC capabilities across a wide range of use-cases ranging from traditional HPC to enterprise and hyper-scale workloads.]]></description><link>https://hpcng.org</link><generator>GatsbyJS</generator><lastBuildDate>Thu, 13 May 2021 12:39:17 GMT</lastBuildDate><item><title><![CDATA[Organizational Structure]]></title><description><![CDATA[Preamble The purpose of this document is to articulate the motivation behind the organizational structure of The Next Generation of High…]]></description><link>https://hpcng.org/organizational-structure/</link><guid isPermaLink="false">https://hpcng.org/organizational-structure/</guid><content:encoded>&lt;h3&gt;Preamble&lt;/h3&gt;
&lt;p&gt;The purpose of this document is to articulate the motivation behind the organizational structure of The Next Generation of High-Performance Computing (HPCng).&lt;/p&gt;
&lt;h3&gt;Structure&lt;/h3&gt;
&lt;p&gt;To be determined&lt;/p&gt;</content:encoded></item><item><title><![CDATA[Privacy Policy]]></title><description><![CDATA[Last Updated: May 13th, 2021 This Privacy Policy describes the information we collect from you, how we use that information and our legal…]]></description><link>https://hpcng.org/privacy-policy/</link><guid isPermaLink="false">https://hpcng.org/privacy-policy/</guid><content:encoded>&lt;p&gt;Last Updated: May 13th, 2021&lt;/p&gt;
&lt;p&gt;This Privacy Policy describes the information we collect from you, how we use that information and our legal basis for doing so. This Privacy Policy applies to the information that we obtain through your use of HPCng websites, and services, including its subdomains singularity.hpcng.org, warewulf.hpcng.org, etc. (collectively, the “Services”), and about our volunteers, sponsors, partners, and users.&lt;/p&gt;
&lt;p&gt;Unless explicitly noted, this Privacy Policy does not cover 3rd party services or mirror sites used by HPCng.&lt;/p&gt;
&lt;hr&gt;
&lt;h2&gt;Who are we?&lt;/h2&gt;
&lt;p&gt;&lt;a href=&quot;https://hpcng.org&quot;&gt;HPCng&lt;/a&gt; is an open source project brought to you by many contributors around the globe. If you have any questions about this privacy policy, please contact our privacy team at privacy@hpcng.org. We will never sell your personal data to anyone and we strongly believe in the right to privacy and anonymity.&lt;/p&gt;
&lt;hr&gt;
&lt;h2&gt;What Data Do We Collect and Receive?&lt;/h2&gt;
&lt;p&gt;In order for us to both provide and maintain our Services, we collect certain information, including through &lt;a href=&quot;https://matomo.org&quot;&gt;Matomo&lt;/a&gt; for analytics on our websites. Depending on your use of the Services, we may collect the following information:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Information you provide when you contact us&lt;/strong&gt; – for example, when you ask for support, send us questions or comments, or report a problem, we will collect any information you provide to us, at a minimum including your email address, and message. We use this data in connection with answering the queries we receive.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Usage data&lt;/strong&gt; – when you use or visit any of our sites or services (e.g. YUM/DNF), unless explicitly noted, we do collect your IP address, browser user agent, operating system, geolocation, and referring website (when applicable). We log this data in order to maintain metrics, troubleshoot and maintain our services.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Information you provide when you create an account&lt;/strong&gt; – when you sign up for and open an account on our account services page, chat service, or forum we may ask you to provide us with information such as your name, email address and other details. As otherwise detailed in this Privacy Policy, we will process this information to provide you with the service you signed up for.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Information to authenticate to our services&lt;/strong&gt; – We store the IP address used to authenticate to our services.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;User activity data for HPCng-hosted applications&lt;/strong&gt; – Any data voluntarily provided to us through the use of HPCng-provided services, including, but not limited to, user profile information, communication history, and direct messages. We use this data for the functionality of 3rd Party Service Providers listed below and for purposes of the HPCng.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Information you provide as a contributor and/or user&lt;/strong&gt; – We may collect information according to the type of contribution you provide. For example, if you are voluntarily testing our images or reporting bugs to us, in order to reproduce, troubleshoot, or validate those bugs, we may record things such as your operating system version, the system specifications of your computer (CPU, RAM, other hardware details), or packages and software versions installed on your computer.&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2&gt;Sharing of Data&lt;/h2&gt;
&lt;p&gt;We share information collected about you with certain selected third parties (“3rd Party Service Providers”) listed below.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Service&lt;/th&gt;
&lt;th&gt;Usage&lt;/th&gt;
&lt;th&gt;Direct Privacy Policy&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;GitHub&lt;/td&gt;
&lt;td&gt;Source control, collaboration, registry, actions&lt;/td&gt;
&lt;td&gt;&lt;a href=&quot;https://docs.github.com/en/github/site-policy/github-privacy-statement&quot;&gt;Privacy Policy&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Figma&lt;/td&gt;
&lt;td&gt;Design collaboration&lt;/td&gt;
&lt;td&gt;&lt;a href=&quot;https://www.figma.com/privacy&quot;&gt;Privacy Policy&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Google Workspace&lt;/td&gt;
&lt;td&gt;Communication, collaboration&lt;/td&gt;
&lt;td&gt;&lt;a href=&quot;https://policies.google.com/privacy?hl=en-US&quot;&gt;Privacy Policy&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Cloudflare&lt;/td&gt;
&lt;td&gt;DNS&lt;/td&gt;
&lt;td&gt;&lt;a href=&quot;https://www.cloudflare.com/privacypolicy/&quot;&gt;Privacy Policy&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Zoom&lt;/td&gt;
&lt;td&gt;Video conferencing&lt;/td&gt;
&lt;td&gt;&lt;a href=&quot;https://zoom.us/privacy/&quot;&gt;Privacy Policy&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Slack&lt;/td&gt;
&lt;td&gt;Chat&lt;/td&gt;
&lt;td&gt;&lt;a href=&quot;https://slack.com/trust/privacy/privacy-policy&quot;&gt;Privacy Policy&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;In addition to the above list of recipients, we may also share your information (i) with mirror sites, (ii) with service providers, including providers of professional advisory services, (iii) when required by a valid subpoena or court order, or as otherwise required by applicable law, regulation, legal or judicial process, (iv) in connection with an asset sale, merger, bankruptcy or other business transaction, (v) to enforce any applicable terms of service or agreements, (vi) to ensure the safety and security of our Services and users, and (vii) when you request we share certain information with third parties.&lt;/p&gt;
&lt;p&gt;We do not sell information collected about you.&lt;/p&gt;
&lt;hr&gt;
&lt;h2&gt;Do Not Track and Cookie Controls&lt;/h2&gt;
&lt;p&gt;&lt;u&gt;Do Not Track Signals:&lt;/u&gt; “Do not track” signals are preferences that users can set on their web browsers to limit how their activity is tracked across online services. Our Services may not all respond to “do not track” signals in your web browser.&lt;/p&gt;
&lt;p&gt;&lt;u&gt;Cookies:&lt;/u&gt; You may control the way in which your devices permit the use of cookies and other tracking technologies. If you so choose, you may block or delete our cookies from your browser; however, blocking or deleting cookies may cause some aspects of the Services to work incorrectly. Most browsers accept cookies automatically. However, you may be able to configure your browser settings to use the Services without some cookie functionality. You can delete cookies manually or set your browser to automatically delete cookies on a pre-determined schedule.&lt;/p&gt;
&lt;hr&gt;
&lt;h2&gt;California Rights Under the CCPA&lt;/h2&gt;
&lt;p&gt;Where applicable, if you are a California resident you may have the following rights under the California Consumer Privacy Act of 2018 (the “CCPA”) in relation to “personal information” we have collected about you as defined in the CCPA; these rights are to the extent required by the CCPA and subject to verification and any applicable exceptions:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;em&gt;Right to Know/Access:&lt;/em&gt; You have the right to request that we disclose certain information to you about our collection and use of certain personal information about you as described below:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;the specific pieces of personal information collected;&lt;/li&gt;
&lt;li&gt;the categories of personal information collected;&lt;/li&gt;
&lt;li&gt;the categories of sources from whom the personal information is collected;&lt;/li&gt;
&lt;li&gt;the purpose for collecting the personal information; and&lt;/li&gt;
&lt;li&gt;the categories of third parties with whom we have shared the personal information.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Right to Delete:&lt;/em&gt; You have the right to request that we delete the personal information.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;To request your exercise of the rights described above, please submit a request to us via one of the contact methods identified below.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Freedom from Discrimination:&lt;/em&gt; You have the right to be free from unlawful discrimination for exercising any of the rights above.&lt;/p&gt;
&lt;p&gt;We will need to verify your identity prior to addressing your request. Only you, or someone legally authorized to act on your behalf, may make a verifiable consumer request related to personal information collected about you. To designate an authorized agent, the authorized agent must provide sufficient information that allows us to reasonably verify that they have been authorized by you to act on their behalf.&lt;/p&gt;
&lt;hr&gt;
&lt;h2&gt;Retention of data&lt;/h2&gt;
&lt;p&gt;We will retain your information as long as your account is active, as necessary to provide you with the services or as otherwise set forth in this Policy. We will also retain and use this information as necessary for the purposes set out in this Policy and to the extent necessary to comply with our legal obligations, resolve disputes, enforce our agreements and protect Rocky Enterprise Software Foundation’s legal rights.&lt;/p&gt;
&lt;hr&gt;
&lt;h2&gt;Information Security Risks&lt;/h2&gt;
&lt;p&gt;While we maintain certain policies to protect information that we may collect from you, no method of transmission over the Internet is completely secure. Therefore, while we strive to protect information about you that we collect, we cannot guarantee absolute security and confidentiality.&lt;/p&gt;
&lt;hr&gt;
&lt;h2&gt;Third Party Websites&lt;/h2&gt;
&lt;p&gt;Our Services may from time to time contain links to other external websites or mirror sites. This Privacy Policy does not apply to third-party websites or mirror sites. We do not control and are not responsible for the privacy practices or the content of third-party websites or mirror sites.&lt;/p&gt;
&lt;hr&gt;
&lt;h2&gt;Privacy Policy Changes&lt;/h2&gt;
&lt;p&gt;We may update this Policy from time to time. If we do, we’ll update the “Last Updated” date at the top of this Privacy Policy. If we make any material changes, we will take steps as required by law, including by notifying you through the Services, sending you an email, or obtaining your consent. The updated Privacy Policy will be effective as of the time of posting, or such later date as may be specified in the updated Privacy Policy.&lt;/p&gt;
&lt;hr&gt;
&lt;h2&gt;Contact Us&lt;/h2&gt;
&lt;p&gt;If you have any questions or concerns regarding your information, please contact us via email at privacy@hpcng.org or physical mail at:&lt;/p&gt;
&lt;p&gt;The Next Generation of High-Performance Computing
Attn: Privacy Matters
1191 Solano Ave. Unit 6850
Albany CA 94706&lt;/p&gt;</content:encoded></item><item><title><![CDATA[Community Charter]]></title><description><![CDATA[Before you read this… This document is a draft! Please comment or suggest changes on GitHub, or send an email to the HPCng organization lead…]]></description><link>https://hpcng.org/community-charter/</link><guid isPermaLink="false">https://hpcng.org/community-charter/</guid><content:encoded>&lt;p&gt;&lt;strong&gt;Before you read this…&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;This document is a draft!&lt;/strong&gt; Please comment or suggest changes on &lt;a href=&quot;https://github.com/hpcng/hpcng.org/blob/master/content/pages/community-charter.md&quot;&gt;GitHub&lt;/a&gt;, or send an email to the HPCng organization lead Gregory Kurtzer at gmk@hpcng.org.&lt;/p&gt;
&lt;h2&gt;Purpose&lt;/h2&gt;
&lt;p&gt;The purpose of this document is to introduce you to, and better define, the Next Generation of High-Performance Computing (HPCng) community, including its community and development goals. This document is a work in progress and feedback, comments, and suggestions are encouraged.&lt;/p&gt;
&lt;h2&gt;Background&lt;/h2&gt;
&lt;p&gt;High-Performance Computing (HPC), a once niche use-case, has been growing in terms of applicability over the last several years. We are seeing large scale, tightly integrated HPC resources beginning to run non-traditional HPC workloads in what we commonly refer to as “the long tail of scientific computing.” As that long tail is growing, it is becoming increasingly common for new applications, use-cases, and science domains to be making use of traditional high-performance computing infrastructures. Additionally, HPC adoption is growing beyond traditional scientific use-cases and into the enterprise through the advent of artificial intelligence training as well as compute and data-driven analytics.&lt;/p&gt;
&lt;p&gt;When we refer to HPC today, we no longer are referring only to those tightly coupled parallel Message Passing Interface (MPI) based applications. We are referring to any application, or series of applications, which are designed to run a given workload as fast as the hardware will allow. This usually means that the performance-critical application will utilize a given subsystem of a hardware stack completely, whether that be CPU, memory, storage, network, GPU, PCI, etc. This could be on a single compute node, a massive GPU workhorse, CPU farm, or a tightly coupled parallel processing infrastructure. For the purpose of this charter, HPC inclusively refers to all of these types of workloads as HPC.&lt;/p&gt;
&lt;p&gt;While “HPC” is becoming increasingly diverse, the architecture to which it is built has not changed considerably over the past two-and-a half decades. This base architecture, commonly referred to as the &lt;a href=&quot;https://en.wikipedia.org/wiki/Beowulf_cluster&quot;&gt;“Beowulf”&lt;/a&gt; design, is predisposed to being flat, isolated, and discrete, which has imposed difficulties with integration of non-HPC specific capabilities like, orchestration, CI/CD and DevOps integration, security process, accountability, and data management (more information below).&lt;/p&gt;
&lt;p&gt;To loosely quote an anonymous venture capitalist:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;There are clearly two parties going on: one in HPC, and one in enterprise.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;This divide has been increasingly causing separation as enterprise architectures, like micro-services, containers, orchestration, etc., have been readily innovating over the past decade and creating a lot of opportunities for optimization of development, operations, security, automation, reliability, and scale. But these new capabilities are not easily transcribed into the HPC sector due to misalignments of base architectures, and thus cross-pollination is not occurring. This leads to the replication of technology and a lack of benefit of experience and capabilities for everyone. &lt;/p&gt;
&lt;p&gt;HPCng strives to build a community of diverse brilliant people to consider these challenges and work together on solutions. &lt;/p&gt;
&lt;h2&gt;Goals&lt;/h2&gt;
&lt;h3&gt;Community&lt;/h3&gt;
&lt;p&gt;We, the members of the HPCng community, strive to create a diverse community of backgrounds, ideas, skill sets, and perspectives. Such diverse perspectives are needed to unite the currently disparate capabilities of HPC and enterprise to allow for running advanced computational and data analytics at scale. &lt;/p&gt;
&lt;p&gt;Engaging with these respective communities will enable a greater understanding of requirements as well as existing technologies that could be used as part of this vision. This will facilitate cross-pollination to create technologies and solve problems across the ecosystem related to incompatible technologies and architectures between traditional Enterprise IT and HPC.&lt;/p&gt;
&lt;h3&gt;Collaboration&lt;/h3&gt;
&lt;p&gt;Referring back to the two party analogy in the abovementioned background, very few people intermingle between these parties, even when a single organization (like oil and gas, pharmaceuticals, aerospace, etc.) hosts both parties. Further, it could be said that the misalignment between HPC and enterprise is detrimental to both communities. On the other hand, there is value both can offer to each other by leveraging the best capabilities across the ecosystem. Thus, we strive to unite these parties and technologies where it makes sense, create new technologies and methodologies as needed, and build the appropriate bridges. We believe that the best way to build these capabilities is not by corporate direction, but rather led by a community of people that this directly affects, where everyone is a stakeholder.&lt;/p&gt;
&lt;h3&gt;Goals&lt;/h3&gt;
&lt;p&gt;Using the above metaphor, while the technical expertise between both parties is obviously quite specialized, it is important for these parties to benefit from each other’s experience, capabilities, and technologies when applicable. There is an outcome here where some amount of infrastructure can be easily shared between enterprise use cases (AI/ML, inference, compute and data driven analytics, etc.) as well as HPC and computational use cases (simulation, modeling, rendering, prediction, analysis, research, and science).&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;“The convergence of AI, data analytics and traditional simulation will result in systems with broader capabilities and configurability as well as cross pollination.” —  Dr. Al Gara, Intel&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3&gt;Projects&lt;/h3&gt;
&lt;p&gt;We strive to develop a collection of open source, community driven projects that represent the next generation of high performance computing system infrastructure. As such infrastructure naturally spans beyond a single utility, the HPCng effort is split into several projects and focus areas. &lt;/p&gt;
&lt;h2&gt;Projects / Focus Areas&lt;/h2&gt;
&lt;p&gt;Moving forward, there are many opportunities to further modernize HPC. The projects and ideas stated here are only designed as a starting point and will surely develop over time through the involvement of stakeholders, technology advancements, and identified needs. The following projects (existing and not yet started) represent the scope of ideas that are to be worked on by HPCng. &lt;/p&gt;
&lt;h3&gt;Workflows&lt;/h3&gt;
&lt;p&gt;HPC has moved beyond just traditional HPC and the “Long Tail of Science” is now swallowing the system. As a result, there is an increasing variety of different kinds of work being done on today’s HPC clusters. For example, there are traditional tightly-coupled parallel jobs, loose coupled parallel jobs, threaded, serial, multiple variants of MPI, services, dependencies, pipelines, dependencies, job arrays, etc.&lt;/p&gt;
&lt;p&gt;The next generation of HPC infrastructure must be able to handle these diverse workloads, dependencies, and job and data orchestration to enable both traditional parallel jobs and non-traditional HPC jobs.&lt;/p&gt;
&lt;h3&gt;Orchestration&lt;/h3&gt;
&lt;p&gt;There are several orchestration systems being widely utilized for enterprise, some of which are also being considered for performance critical workloads (e.g., Kubernetes and Nomad). There are two ways to consider orchestration of workloads:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Running HPC workloads directly through the orchestrator:&lt;/strong&gt; There are a number of people considering running HPC workloads directly from Kubernetes, most of which have only been successful for the most rudimentary of workloads and scheduling policies. There is clearly a lot of work to do to achieve full parity with existing HPC requirements for scheduling and workload management. Strategy is needed here.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Meta-scheduling HPC with an orchestrator:&lt;/strong&gt; It is possible to use an orchestrator to implement meta-scheduling of HPC workloads to multiple clusters and workload management systems like Slurm, PBS, Grid Engine, etc. Several such projects are currently known for this (if there are more, let us know): Multicluster-Scheduler, HTCondor, and WLM-Operator.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Singularity/Containers&lt;/h3&gt;
&lt;p&gt;Singularity is a fantastic initial step in the modernization of HPC as it allows containers (a technology derived from enterprise focused innovation) to be leveraged and extended upon within traditional HPC contexts. Singularity, while popular and widespread in the community, is not the only container system being used. Other container runtimes including Shifter, CharlieCloud, and Sarus, are also utilized in various other scenarios. While container runtimes are an important building block in the next generation of HPC, they are a single piece of the puzzle.&lt;/p&gt;
&lt;p&gt;Please note: Singularity has already been moved to the HPCng community GitHub organization and is now available at: &lt;a href=&quot;https://github.com/hpcng/singularity/&quot;&gt;https://github.com/hpcng/singularity/&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Cluster Management and Provisioning&lt;/h3&gt;
&lt;p&gt;There are multiple ways to manage HPC clusters, (Warewulf being one of them that HPC centers have direct experience with) but they do not currently solve all of the problems that we are experiencing with both large and small clusters, nor do they integrate well into enterprise computing environments for the same reasons that legacy HPC misaligns with enterprise architectures. It is our goal to help and modernize this initiative.&lt;/p&gt;
&lt;p&gt;Warewulf has not yet moved into HPCng, but we are hoping to have that occur very soon now.&lt;/p&gt;
&lt;h3&gt;Public Key Infrastructure&lt;/h3&gt;
&lt;p&gt;Singularity supports its own key management paradigm and leverages standard HKP (Horowitz Keyserver Protocol), but it needs to be extended to completely support Synchronizing Key Server (SKS) Pools and the Notary container standard currently being developed.&lt;/p&gt;
&lt;h3&gt;Secrets Management&lt;/h3&gt;
&lt;p&gt;Encryption of containers is possible with Singularity, and due to its container image format, SIF, when used, can run containers directly from an encrypted format. While this can already be used with Singularity to manage secrets and decryption, it is not well integrated and can not operate well with orchestration systems today like cloud hosted Kubernetes.&lt;/p&gt;
&lt;h3&gt;CI/CD Integration&lt;/h3&gt;
&lt;p&gt;Continuous Integration and Continuous Deployment (CI/CD) is a method of automating, accelerating, and testing software from SCM (Source Code Management) to production. Containers are the default portable output format (artifact) from these CI/CD pipelines and are currently being used widely in enterprise deployments.&lt;/p&gt;
&lt;p&gt;Integrating this process into HPC workflows can bring similar benefits to HPC environments as well as providing trusted software stacks leveraging cryptographic validation on all workloads that come out of the CI/CD pipeline providing 100% trust and validity.&lt;/p&gt;
&lt;h3&gt;Hybrid-Location Federated HPC&lt;/h3&gt;
&lt;p&gt;More and more, people are interested in leveraging additional resources for computing involving multiple systems, on-prem, off-prem, cloud, multi-cloud, etc. We have various capabilities being offered in the cloud (AWS, Azure Batch, Rescale, Ubercloud, Atrio, etc.), but we don’t have a suitable mechanism for making workloads or data hybrid-capable. Data platforms like Globus, RStor, OpenDrives, Wasabi, as well as self-hosted deployments of Ceph and/or Minio could be a suitable backend for global data migration, but we still need a way to tie that directly to the workloads.  &lt;/p&gt;
&lt;p&gt;Another consideration is that once many locations are involved in handling a single workload, another immediate issue that arises is a common, secure software distribution platform that performs well over a wide area, and scales to very large numbers of nodes. This can be done via a distributed file system (perhaps CVMFS as an option) or a distributed caching system which works in conjunction with the orchestration and workflow engine. &lt;/p&gt;
&lt;h3&gt;Reproducibility/Trust&lt;/h3&gt;
&lt;p&gt;Reproducibility in science is a critical problem to solve so we can have confidence in the software environments that we are running in. While we can’t solve it for the entire stack (e.g. hardware), we can solve it for the software stack. The answer to reproducibility and compliance is trust and assurance.&lt;/p&gt;
&lt;p&gt;The ability to tag a workload with a cryptographic signature allows for not only validation but also accountability. Containers, being the basic building block moving forward, allows us to gain strong confidence in the environments we are running within, but we are not completely there yet.&lt;/p&gt;
&lt;p&gt;We still need the control surface necessary to manage not only the containers, but also the cryptographic and secure materials needed to guarantee trust.&lt;/p&gt;
&lt;p&gt;Note, this is related to the PKI focus area above but offers additional capabilities around computational use cases and controls compliance like FDA and FAA software stack regulations.&lt;/p&gt;
&lt;h3&gt;Composable Hardware&lt;/h3&gt;
&lt;p&gt;The HPC of the future will consist of not only complex schedulers, software stacks, and data flows, but many different hardware components, ranging from continuing evolution of CPUs and GPUs to more domain-specific accelerators purpose built to support complex computational workflows. HPC must be able to effectively and dynamically “compose” complex hardware topologies leveraging next generation memory semantic fabrics, such as GenZ and CXL. &lt;/p&gt;
&lt;h3&gt;MPI and InfiniBand Container integration&lt;/h3&gt;
&lt;p&gt;While leveraging MPI through containers has been largely accomplished and MPI is now moving into enterprise workloads like AI training via Horovod, there are a number of areas that can still be further addressed for building, running, and maintaining MPI based containers. Additionally, the libraries and host/kernel dependencies and Application Binary Interfaces (ABI) communication pathways (e.g., OFED) still need to be more universally addressed.&lt;/p&gt;
&lt;h3&gt;OCP/Hyper-scale&lt;/h3&gt;
&lt;p&gt;There have been significant advances in the hyper-scale space for very efficient and scalable hardware designs, but almost nobody in HPC is leveraging these capabilities. It is advantageous for HPC to be part of the OCP community, and the hyper-scale “scale-up” architecture is highly advantageous, and can (in theory) be used very well for HPC use-cases.&lt;/p&gt;
&lt;h3&gt;Service Mesh and Service Discovery&lt;/h3&gt;
&lt;p&gt;There is much room for improvement in the traditional HPC space for Service Mesh (think Istio and Hashicorp’s Consul) and Service Discovery. These technologies could be adopted/augmented and leveraged to provide container, service information, and intelligence (health, capabilities, address information, etc.) to enhance the capabilities of HPC, allowing for self-healing and scaling, among other uses. &lt;/p&gt;
&lt;h3&gt;Storage Agnostic Layers&lt;/h3&gt;
&lt;p&gt;There is a need for HPCng to have a broad support for different storage methodologies and types in order to gain maximum scalability and functionality. Storage considerations for HPC are usually designed for the task at hand, rather than general purpose. HPC 2.0 needs to be able to ingest and consume storage of many disparate types and present them in a way (perhaps using a service mesh) to jobs that are run to match the appropriate storage to its job type. This is sometimes leveraged through job schedulers such as SLURM via &lt;code class=&quot;language-text&quot;&gt;--hint&lt;/code&gt; style options for CPU architectures — this type of design could be implemented for storage as well. &lt;/p&gt;
&lt;p&gt;There are many more initiatives that still need to be identified, as well as goals for this community. This is only meant as a starting point and should be fleshed out with time and collaboration. Please add comments to any of the above ideas, or feel free to write your own to the list.&lt;/p&gt;
&lt;h2&gt;Corporate Structure&lt;/h2&gt;
&lt;p&gt;The goal of HPCng is to become a tax exempt non-profit, both in the US as well as abroad (e.g., Switzerland). This is a long and arduous process here in the US but this is the shared goal of the HPCng Board of Directors.&lt;/p&gt;
&lt;h3&gt;Board of Directors&lt;/h3&gt;
&lt;p&gt;As of the first draft of this document, HPCng has been founded and led by a sole individual, Gregory M. Kurtzer. Moving forward, Kurtzer has identified the necessity for the leadership to be more than that of a single individual or single company. To this point, Kurtzer has created an HPCng Board of Directors (HBOD) which will be used to share the leadership and decision making responsibilities to an initially invited board.&lt;/p&gt;
&lt;p&gt;At the time of this writing, the confirmed board members are as follows:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Andrew Younge, PhD: Computer Scientist, Sandia National Laboratories, DOE&lt;/li&gt;
&lt;li&gt;Brent Gorda: Senior Director of HPC at ARM, Inc.&lt;/li&gt;
&lt;li&gt;Brock Taylor: Director of HPC Solutions at AMD, Inc.&lt;/li&gt;
&lt;li&gt;Glen Otero, PhD: Vice President of Scientific Computing, TGen&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;With Gregory M. Kurtzer taking the role of Chairman of the Board.&lt;/p&gt;
&lt;p&gt;The roles of the HBOD are as follows (but not limited to therein, as the structure is still developing):&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Establish vision, mission, and values of HPCng&lt;/li&gt;
&lt;li&gt;Approve, agree, and amend the necessary documents (including this charter)&lt;/li&gt;
&lt;li&gt;Be an escalation point of authority for decision making process when necessary&lt;/li&gt;
&lt;li&gt;Define and maintain the board members themselves&lt;/li&gt;
&lt;li&gt;Appoint the leadership of HPCng whom will execute the vision, mission, and values of the organization&lt;/li&gt;
&lt;li&gt;Ensure proper communication and transparency in being an open community and organization
Handle the establishment of the financial and legal structure of HPCng&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In summation, the HBOD is responsible for the high level structure, organization, and vision, not the day-to-day management of the organization.&lt;/p&gt;
&lt;h3&gt;Management Structure&lt;/h3&gt;
&lt;p&gt;As the HBOD is predominantly responsible for high level matters of HPCng, day-to-day responsibility will be undertaken by the management team.&lt;/p&gt;
&lt;p&gt;The roles and responsibilities of this management team is still being decided upon, but we are aware of some basic and critical roles already:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Executive Director&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Director of Operations&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Systems infrastructure management&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Director of communications/PR&lt;/li&gt;
&lt;li&gt;Secretary/Admin &lt;/li&gt;
&lt;li&gt;Community Manager&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The roles and responsibilities of the management team are currently being discussed and evolving.&lt;/p&gt;
&lt;h2&gt;Discussions and collaboration&lt;/h2&gt;
&lt;p&gt;We will hold recurring meetings to facilitate collaboration on the above topics, discuss additional topics of interest, organize teams, presentations, and votes. Attendance to these meetings will be open to anybody who wishes to join, and everyone is encouraged to be part of these.&lt;/p&gt;
&lt;p&gt;Agendas will be posted and everybody can influence the discussions.&lt;/p&gt;
&lt;h2&gt;In the Nature of Open Source&lt;/h2&gt;
&lt;p&gt;Corporate involvement and contributions to HPCng will be essential to driving adoption and creating robust infrastructure for the future of HPC. To encourage and invite corporate support, there needs to be paths for products and services built on top of HPCng. In the same light, there must also be paths that do not require any proprietary or commercial products. This allows commercial entities, big and small, to participate and contribute to create a level playing field with opportunities for differentiating through innovation on top of HPCng. It also ensures that the base benefits of HPCng are freely available and provide significant value to all users without the need for commercial or proprietary components. With commercial extensions and service opportunities, HPCng can expect more inputs and contributions from technical and business resources from corporate entities in HPC. &lt;/p&gt;
&lt;p&gt;No open source project will have non-OSI licensed or restricted software or API requirements without an exemption from the HPCng Board of Directors (e.g. NVidia Cuda). HPCng will always leverage open API requirements and ensure that an open source path exists, even if that is a limited reference implementation. HPCng requires that all APIs and interfaces of hosted projects are open source and freely available (e.g. OSI approved licenses). The process for requesting an exemption will be determined at a later time.&lt;/p&gt;
&lt;p&gt;We ask that all other people and organizations who wish to be part of the HPCng community to do the same. Companies who benefit from the discussions and insights from the community should also release any resulting projects, software, and/or documentation which was inspired by this community as open source, preferably within this community’s GitHub organization. In doing so, the contributing leading organizations will be administrators of that project and have a delegate membership in the HPCng organization. All developers will also be able to leverage infrastructure that will be built up for all projects, and founders of projects will maintain authority.&lt;/p&gt;
&lt;p&gt;HPCng is designed to be community focused, and any participating corporations should not use HPCng as a marketing opportunity to drive products and sales, but rather as a platform to drive features, capabilities, and collaboration.&lt;/p&gt;
&lt;h2&gt;Security Protocol&lt;/h2&gt;
&lt;p&gt;There are challenges in the open source community with how best to address and resolve security issues. This is a rough guideline and will be further fleshed out on how we will handle security issues for any of the HPCng projects:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Security report is made to the HPCng security team members&lt;/li&gt;
&lt;li&gt;Security diligence will be done and severity of the issue will be ascertained&lt;/li&gt;
&lt;li&gt;If the issue is not deemed to have security implications, this process stops and embargo is lifted&lt;/li&gt;
&lt;li&gt;The HPCng security team (and the reporter) will work together to find a reasonable solution and/or mitigation&lt;/li&gt;
&lt;li&gt;Project security stakeholders will all be under contracted embargo to keep security context and information confidential until a full public release and disclosure is made (note: a security team vendor could in fact make a fix before one is agreed upon and release that without a security disclosure to their commercial user base)&lt;/li&gt;
&lt;li&gt;The release of the fix and lift of embargo will occur after sufficient testing and agreement by the security team stakeholders (note: releases for zero-day exploits will be expedited)&lt;/li&gt;
&lt;li&gt;CVEs will be obtained for security releases&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;If you wish to be on the HPCng security team, or have a security issue to discuss for any of the HPCng projects, please contact the HPCng security team at security@hpcng.org.&lt;/p&gt;
&lt;h2&gt;Challenges&lt;/h2&gt;
&lt;p&gt;There are some challenges that are already foreseen, and we’re sure more will arise. These include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Refining the early messaging (the text in this document)&lt;/li&gt;
&lt;li&gt;Getting the word out about what we are doing&lt;/li&gt;
&lt;li&gt;Engagement with the community&lt;/li&gt;
&lt;li&gt;Balancing the load (it shouldn’t be a small number of people doing all the work)&lt;/li&gt;
&lt;li&gt;Infrastructure management&lt;/li&gt;
&lt;li&gt;Volunteering&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This is where we will need help, discussions, and volunteers.&lt;/p&gt;
&lt;h2&gt;Call-To-Action&lt;/h2&gt;
&lt;p&gt;Join the HPCng community &lt;a href=&quot;https://join.slack.com/t/hpcng/shared_invite/zt-qda4h1ls-OP0Uouq6sSmVE6i_0NrWdw&quot;&gt;Slack team&lt;/a&gt;, join the channels you are interested in being part of, and introduce yourself to us!&lt;/p&gt;</content:encoded></item><item><title><![CDATA[Full Steam Ahead!]]></title><description><![CDATA[Dear Singularity Community, I believe that open source projects should be stable, freely available, and give confidence to everyone who…]]></description><link>https://hpcng.org/news/full-steam-ahead/</link><guid isPermaLink="false">https://hpcng.org/news/full-steam-ahead/</guid><pubDate>Fri, 07 May 2021 00:00:00 GMT</pubDate><content:encoded>&lt;p&gt;Dear Singularity Community,&lt;/p&gt;
&lt;p&gt;I believe that open source projects should be stable, freely available, and give confidence to everyone who depends on them.&lt;/p&gt;
&lt;p&gt;One good way to do this is to create an open governance structure that is comprised of a diverse group of organizations while being beholden to none individually.&lt;/p&gt;
&lt;p&gt;To that point, HPCng was formed with two visions: to modernize HPC environments and to build a multi-organization community around this vision. Today, we have involvement from a diverse group of industry, academic, and government partners. Our board is made up of 5 truly great people with a proven track record in HPC. We have a community charter which was developed collaboratively among many organizations completely in the open, for anyone who wants to take part and contribute. This is the same with the management team and all roles within the organization. HPCng was created for the public benefit of the HPC community. This is the organization that Singularity and Warewulf are now proudly part of.&lt;/p&gt;
&lt;p&gt;Earlier this week Sylabs announced that they are forking the Singularity project from HPCng and into their own private organization. As many of you in this community have since pointed out, forking an open source project does not serve the community. While this situation is unfortunate, it is allowed by the Singularity license. However, there has been one major resounding request from the community: for Sylabs to rebrand their fork so as to not cause massive confusion as the projects drift apart. Keeping the same name would conflate bug reports, versions, feature variances, documentation, media, branding, security notices, and the projects themselves.&lt;/p&gt;
&lt;p&gt;Moving forward, we feel this event forces us to accelerate the desired growth within the Singularity project. I will continue to commit resources from my company (CIQ) to help smooth this transition which include the senior Singularity developers (and myself) who have been responsible for building, designing, and architecturing the vast majority of Singularity. But we need more than that, we need your help… participants, volunteers, contributors, leads, managers, maintainers, etc., to take on responsibilities within the project and help guide the direction of the project and HPCng. If you want to be part of this initiative, please join the Slack and say hello (or email me directly), I’d love to hear from you!&lt;/p&gt;
&lt;p&gt;The HPCng board of directors have already been recruiting other organizations and individuals to join and we are currently expanding the project. For example, Brock Taylor (the HPCng Executive Director and Board Member) has been doing a fantastic job pitching the organization to raise awareness about the modernization of HPC and there are a number of large organizations interested in joining this initiative. Also, we are seeing a lot of interest from the cross pollination with enterprise computing use-cases via the visibility that Rocky Linux has created as well as the common lineage from HPCng.&lt;/p&gt;
&lt;p&gt;It will take us a bit of time to regroup so that we can finish up and get Singularity 3.8 released, and the roadmap for 4.0 and beyond, so stay tuned!&lt;/p&gt;
&lt;p&gt;Thank you for your continued support of Singularity.&lt;/p&gt;
&lt;p&gt;—&lt;/p&gt;
&lt;p&gt;Gregory M. Kurtzer (CIQ) - Founder and project lead of Singularity, board member of HPCng&lt;/p&gt;
&lt;p&gt;With the concurrence of:&lt;/p&gt;
&lt;p&gt;Andrew Younge (Sandia National Labs) - Board member of HPCng&lt;/p&gt;
&lt;p&gt;Brent Gorda (ARM)  - Board member of HPCng&lt;/p&gt;
&lt;p&gt;Brock Taylor (AMD) - Executive Director and board member of HPCng&lt;/p&gt;
&lt;p&gt;Cedric Clerget (CIQ) - Singularity Core Developer and Maintainer&lt;/p&gt;
&lt;p&gt;Dave Dykstra (Fermi National Lab) - HPCng management team and Singularity contributor&lt;/p&gt;
&lt;p&gt;Glen Otero (TGen) - Board member of HPCng&lt;/p&gt;
&lt;p&gt;Ian Kaneshiro (CIQ) - Singularity Core Developer and Maintainer&lt;/p&gt;
&lt;p&gt;Krishna Muriki (Lawrence Berkeley Lab) - Founding org and HPCng management team&lt;/p&gt;
&lt;p&gt;Patrick Roberts (Goodix) - HPCng management team&lt;/p&gt;</content:encoded></item><item><title><![CDATA[The Next Platform]]></title><description><![CDATA[Read the Article]]></description><link>https://hpcng.org/news/thenextplatform-2020-12-21/</link><guid isPermaLink="false">https://hpcng.org/news/thenextplatform-2020-12-21/</guid><pubDate>Mon, 21 Dec 2020 00:00:00 GMT</pubDate><content:encoded>&lt;p&gt;&lt;a href=&quot;https://www.nextplatform.com/2020/12/21/centos-and-hpc-its-okay-we-are-moving-on/&quot;&gt;Read the Article&lt;/a&gt;&lt;/p&gt;</content:encoded></item></channel></rss>